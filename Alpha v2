{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceType":"datasetVersion","sourceId":14917655,"datasetId":9545058,"databundleVersionId":15783936}],"dockerImageVersionId":31286,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"\"\"\"\nAlpha v2 Streaming Dataset Builder\nHard capped at exactly 7M tokens\nMemory safe (streaming=True)\n\"\"\"\n\nimport random\nimport json\nfrom datasets import load_dataset\nfrom tqdm import tqdm\nimport tiktoken\n\n# ==============================\n# CONFIG\n# ==============================\n\nTARGET_TOTAL_TOKENS = 7_000_000\n\nSPLIT_CONFIG = {\n    \"instruction\": 0.40,\n    \"reasoning\": 0.20,\n    \"code\": 0.15,\n    \"windows\": 0.15,\n    \"clean_text\": 0.10\n}\n\nWINDOWS_FILE_PATH = \"/kaggle/input/datasets/majorlakshya/windows/windows.jsonl\"\nOUTPUT_FILE = \"alpha_v2_7M.jsonl\"\n\nenc = tiktoken.get_encoding(\"gpt2\")\n\ndef count_tokens(text):\n    return len(enc.encode(text))\n\n# ==============================\n# STREAM COLLECTOR\n# ==============================\n\ndef stream_collect(dataset, text_fn, token_budget):\n    selected = []\n    total = 0\n\n    for sample in dataset:\n        text = text_fn(sample)\n        if not text:\n            continue\n\n        tokens = count_tokens(text)\n\n        if total + tokens > token_budget:\n            break\n\n        selected.append(text)\n        total += tokens\n\n    return selected, total\n\n# ==============================\n# WINDOWS LOADER (LOCAL)\n# ==============================\n\ndef stream_windows(path):\n    with open(path, \"r\", encoding=\"utf-8\") as f:\n        for line in f:\n            yield json.loads(line)\n\n# ==============================\n# MAIN\n# ==============================\n\ndef main():\n\n    final_dataset = []\n    total_tokens = 0\n\n    for category, pct in SPLIT_CONFIG.items():\n\n        category_budget = int(TARGET_TOTAL_TOKENS * pct)\n        remaining_global = TARGET_TOTAL_TOKENS - total_tokens\n        category_budget = min(category_budget, remaining_global)\n\n        print(f\"\\nBuilding {category} → Target {category_budget}\")\n\n        if category == \"instruction\":\n\n            alpaca = load_dataset(\"yahma/alpaca-cleaned\", split=\"train\", streaming=True)\n            dolly = load_dataset(\"databricks/databricks-dolly-15k\", split=\"train\", streaming=True)\n\n            data_iter = (\n                (f\"User: {x['instruction']}\\nAssistant: {x['output']}\" for x in alpaca)\n            )\n            collected1, used1 = stream_collect(data_iter, lambda x: x, category_budget)\n\n            remaining = category_budget - used1\n\n            data_iter2 = (\n                (f\"User: {x['instruction']}\\nAssistant: {x['response']}\" for x in dolly)\n            )\n            collected2, used2 = stream_collect(data_iter2, lambda x: x, remaining)\n\n            final_dataset.extend(collected1 + collected2)\n            total_tokens += used1 + used2\n\n        elif category == \"reasoning\":\n\n            gsm8k = load_dataset(\"gsm8k\", \"main\", split=\"train\", streaming=True)\n\n            data_iter = (\n                (f\"Question: {x['question']}\\nAnswer: {x['answer']}\" for x in gsm8k)\n            )\n\n            collected, used = stream_collect(data_iter, lambda x: x, category_budget)\n\n            final_dataset.extend(collected)\n            total_tokens += used\n\n        elif category == \"code\":\n\n            code_ds = load_dataset(\n                \"Programming-Language/codeagent-python\",\n                split=\"train\",\n                streaming=True\n            )\n\n            data_iter = (\n                json.dumps({\n                    \"instruction\": x.get(\"instruction\", \"\"),\n                    \"input\": x.get(\"input\", \"\"),\n                    \"output\": x.get(\"output\", \"\")\n                })\n                for x in code_ds\n            )\n\n            collected, used = stream_collect(data_iter, lambda x: x, category_budget)\n\n            final_dataset.extend(collected)\n            total_tokens += used\n\n        elif category == \"windows\":\n\n            data_iter = (\n                json.dumps(x, ensure_ascii=False)\n                for x in stream_windows(WINDOWS_FILE_PATH)\n            )\n\n            collected, used = stream_collect(data_iter, lambda x: x, category_budget)\n\n            final_dataset.extend(collected)\n            total_tokens += used\n\n        elif category == \"clean_text\":\n\n            openweb = load_dataset(\n                \"Skylion007/openwebtext\",\n                split=\"train\",\n                streaming=True\n            )\n\n            data_iter = (x[\"text\"] for x in openweb)\n\n            collected, used = stream_collect(data_iter, lambda x: x, category_budget)\n\n            final_dataset.extend(collected)\n            total_tokens += used\n\n        print(f\"Running total: {total_tokens}\")\n\n        if total_tokens >= TARGET_TOTAL_TOKENS:\n            break\n\n    # ==============================\n    # TOP-UP IF UNDERFILLED\n    # ==============================\n\n    if total_tokens < TARGET_TOTAL_TOKENS:\n\n        deficit = TARGET_TOTAL_TOKENS - total_tokens\n        print(f\"\\nTop-up required: {deficit}\")\n\n        openweb = load_dataset(\n            \"Skylion007/openwebtext\",\n            split=\"train\",\n            streaming=True\n        )\n\n        data_iter = (x[\"text\"] for x in openweb)\n\n        collected, used = stream_collect(data_iter, lambda x: x, deficit)\n\n        final_dataset.extend(collected)\n        total_tokens += used\n\n    print(f\"\\nFinal token count before cap: {total_tokens}\")\n\n    # ==============================\n    # HARD CAP\n    # ==============================\n\n    random.shuffle(final_dataset)\n\n    capped = []\n    final_count = 0\n\n    for text in final_dataset:\n        tokens = count_tokens(text)\n\n        if final_count + tokens > TARGET_TOTAL_TOKENS:\n            break\n\n        capped.append(text)\n        final_count += tokens\n\n    print(f\"\\nFINAL TOKEN COUNT: {final_count}\")\n\n    # ==============================\n    # SAVE\n    # ==============================\n\n    with open(OUTPUT_FILE, \"w\", encoding=\"utf-8\") as f:\n        for text in capped:\n            f.write(text.strip() + \"\\n\")\n\n    print(f\"\\nSaved dataset to {OUTPUT_FILE}\")\n\nif __name__ == \"__main__\":\n    main()","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2026-02-22T10:38:34.678572Z","iopub.execute_input":"2026-02-22T10:38:34.678941Z","iopub.status.idle":"2026-02-22T10:40:19.999217Z","shell.execute_reply.started":"2026-02-22T10:38:34.678910Z","shell.execute_reply":"2026-02-22T10:40:19.997538Z"}},"outputs":[{"name":"stdout","text":"\nBuilding instruction → Target 2800000\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"README.md: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0629084fb46941e285cfcd2d07761e97"}},"metadata":{}},{"name":"stderr","text":"Warning: You are sending unauthenticated requests to the HF Hub. Please set a HF_TOKEN to enable higher rate limits and faster downloads.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"README.md: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a5b832a1836548429de9031d08c2b908"}},"metadata":{}},{"name":"stdout","text":"Running total: 2799986\n\nBuilding reasoning → Target 1400000\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"README.md: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9ff36700436b4b2a89bf2e070c331932"}},"metadata":{}},{"name":"stdout","text":"Running total: 3959122\n\nBuilding code → Target 1050000\nRunning total: 5009122\n\nBuilding windows → Target 1050000\nRunning total: 6014636\n\nBuilding clean_text → Target 700000\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"README.md: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3b4fdf524fe24931a443bc42d0460767"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Resolving data files:   0%|          | 0/80 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dcc56199f2fc420087cec83e7f8d6c91"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Resolving data files:   0%|          | 0/80 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3ceef41d14424b089915e6e3d8fbb853"}},"metadata":{}},{"name":"stdout","text":"Running total: 6714539\n\nTop-up required: 285461\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Resolving data files:   0%|          | 0/80 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cc0e9db877494b6591c7953a81007464"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Resolving data files:   0%|          | 0/80 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"64f06d56e2f6401187542deab00acc7e"}},"metadata":{}},{"name":"stdout","text":"\nFinal token count before cap: 6999883\n\nFINAL TOKEN COUNT: 6999883\n\nSaved dataset to alpha_v2_7M.jsonl\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import json\nimport pickle\n\nimport random\n\nINPUT_FILE = \"alpha_v2_7M.jsonl\"\nOUTPUT_FILE = \"alpha_v2_7M_Shuffled.jsonl\"\n\nwith open(INPUT_FILE, \"r\", encoding=\"utf-8\") as f:\n    lines = f.readlines()\nprint(f\"Loaded {len(lines)} lines\")\nrandom.shuffle(lines)\n\nwith open(OUTPUT_FILE, \"w\", encoding=\"utf-8\") as f:\n    f.writelines(lines)\n\nprint(\"Shuffled file saved.\")\n\ndata = []\nwith open('alpha_v2_7M.jsonl', 'r', encoding='utf-8') as f:\n    for line in f:\n        data.append(json.loads(line))\n\nwith open('alpha_v2_7M.bin', 'wb') as f:\n    pickle.dump(data, f)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-22T10:44:37.631165Z","iopub.execute_input":"2026-02-22T10:44:37.631585Z","iopub.status.idle":"2026-02-22T10:44:38.107928Z","shell.execute_reply.started":"2026-02-22T10:44:37.631551Z","shell.execute_reply":"2026-02-22T10:44:38.106371Z"}},"outputs":[{"name":"stdout","text":"Loaded 273150 lines\nShuffled file saved.\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_55/2514690138.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'alpha_v2_7M.jsonl'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'alpha_v2_7M.bin'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.12/json/__init__.py\u001b[0m in \u001b[0;36mloads\u001b[0;34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[1;32m    344\u001b[0m             \u001b[0mparse_int\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mparse_float\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    345\u001b[0m             parse_constant is None and object_pairs_hook is None and not kw):\n\u001b[0;32m--> 346\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_default_decoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    347\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcls\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m         \u001b[0mcls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mJSONDecoder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.12/json/decoder.py\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(self, s, _w)\u001b[0m\n\u001b[1;32m    336\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    337\u001b[0m         \"\"\"\n\u001b[0;32m--> 338\u001b[0;31m         \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_w\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    339\u001b[0m         \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_w\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    340\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.12/json/decoder.py\u001b[0m in \u001b[0;36mraw_decode\u001b[0;34m(self, s, idx)\u001b[0m\n\u001b[1;32m    354\u001b[0m             \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscan_once\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    355\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 356\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mJSONDecodeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Expecting value\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    357\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mJSONDecodeError\u001b[0m: Expecting value: line 1 column 1 (char 0)"],"ename":"JSONDecodeError","evalue":"Expecting value: line 1 column 1 (char 0)","output_type":"error"}],"execution_count":2},{"cell_type":"code","source":"import numpy as np\n\ntokens = np.fromfile(\"alpha_v2_7M.bin\", dtype=np.uint16)\n\nsplit = int(len(tokens) * 0.9)\n\ntokens[:split].tofile(\"train.bin\")\ntokens[split:].tofile(\"val.bin\")\n\nprint(\"Train/Val split complete.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-22T10:46:03.092126Z","iopub.execute_input":"2026-02-22T10:46:03.092469Z","iopub.status.idle":"2026-02-22T10:46:03.131746Z","shell.execute_reply.started":"2026-02-22T10:46:03.092439Z","shell.execute_reply":"2026-02-22T10:46:03.130111Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_55/2790659150.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'alpha_v2_7M_Shuffled.jsonl'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'alpha_v2_7M_Shuffled.bin'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.12/json/__init__.py\u001b[0m in \u001b[0;36mloads\u001b[0;34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[1;32m    344\u001b[0m             \u001b[0mparse_int\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mparse_float\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    345\u001b[0m             parse_constant is None and object_pairs_hook is None and not kw):\n\u001b[0;32m--> 346\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_default_decoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    347\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcls\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m         \u001b[0mcls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mJSONDecoder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.12/json/decoder.py\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(self, s, _w)\u001b[0m\n\u001b[1;32m    336\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    337\u001b[0m         \"\"\"\n\u001b[0;32m--> 338\u001b[0;31m         \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_w\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    339\u001b[0m         \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_w\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    340\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.12/json/decoder.py\u001b[0m in \u001b[0;36mraw_decode\u001b[0;34m(self, s, idx)\u001b[0m\n\u001b[1;32m    354\u001b[0m             \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscan_once\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    355\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 356\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mJSONDecodeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Expecting value\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    357\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mJSONDecodeError\u001b[0m: Expecting value: line 1 column 1 (char 0)"],"ename":"JSONDecodeError","evalue":"Expecting value: line 1 column 1 (char 0)","output_type":"error"}],"execution_count":4},{"cell_type":"code","source":"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-22T09:52:34.925483Z","iopub.execute_input":"2026-02-22T09:52:34.925760Z","iopub.status.idle":"2026-02-22T09:52:35.041002Z","shell.execute_reply.started":"2026-02-22T09:52:34.925737Z","shell.execute_reply":"2026-02-22T09:52:35.040053Z"}},"outputs":[{"name":"stdout","text":"Total tokens: 12,780,540\nTrain tokens: 11,502,486\nVal tokens:   1,278,054\nDone. train.bin and val.bin created.\n","output_type":"stream"}],"execution_count":6}]}